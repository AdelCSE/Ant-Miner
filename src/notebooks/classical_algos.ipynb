{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd15bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import wittgenstein as lw\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b666864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATASETS_PATH = \"../../datasets/SLC/\"\n",
    "DATASETS = [\n",
    "    \"mushrooms\", \"tictactoe\", \"hepatitis\", \"ljubljana\", \"cargood\", \n",
    "    \"chess\", \"zoo3\", \"flare\", \"yeast3\", \"abalone19\", \"segment0\", \"pageblocks\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5a5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper: Calculate Specificity ---\n",
    "def calculate_specificity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Specificity (True Negative Rate). \n",
    "    For multiclass, calculates the macro-average specificity.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Binary case\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # Multiclass case (Macro Average)\n",
    "    specificities = []\n",
    "    for i in range(len(cm)):\n",
    "        tn = np.sum(cm) - (np.sum(cm[i, :]) + np.sum(cm[:, i]) - cm[i, i])\n",
    "        fp = np.sum(cm[:, i]) - cm[i, i]\n",
    "        \n",
    "        spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        specificities.append(spec)\n",
    "    \n",
    "    return np.mean(specificities)\n",
    "\n",
    "# --- Helper: Data Loader ---\n",
    "def load_dataset(name, path):\n",
    "    \"\"\"\n",
    "    Attempts to load dataset from path. Assumes CSV format.\n",
    "    Adjust 'sep' or file extension logic if your data varies.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(path, f\"{name}.csv\") # Defaulting to .csv\n",
    "    \n",
    "    # Fallback to .data if .csv missing, common in SLC datasets\n",
    "    if not os.path.exists(file_path):\n",
    "        file_path = os.path.join(path, f\"{name}.data\")\n",
    "        \n",
    "    try:\n",
    "        # Trying common separators\n",
    "        df = pd.read_csv(file_path, sep=None, engine='python')\n",
    "        \n",
    "        # Simple preprocessing: Label Encode target (last column) and categories\n",
    "        le = LabelEncoder()\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = le.fit_transform(df[col].astype(str))\n",
    "                \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df.iloc[:, -1].values\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0806eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Ripper\": lw.RIPPER(), \n",
    "    \"C4.5\": DecisionTreeClassifier(criterion='entropy'),\n",
    "    \"CostSensitive C4.5\": DecisionTreeClassifier(criterion='entropy', class_weight='balanced')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e0902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset         Algorithm            Acc      F1       Recall   Prec     Spec    \n",
      "-------------------------------------------------------------------------------------\n",
      "mushrooms       Ripper               nan   nan   nan   nan   nan\n",
      "mushrooms       C4.5                 0.4849   0.4588   0.4849   0.4414   0.8983\n",
      "mushrooms       CostSensitive C4.5   0.4849   0.5108   0.4849   0.5484   0.9102\n",
      "tictactoe       Ripper               0.9714   0.9711   0.9714   0.9729   0.9403\n",
      "tictactoe       C4.5                 0.8848   0.8838   0.8848   0.8855   0.8085\n",
      "tictactoe       CostSensitive C4.5   0.8879   0.8869   0.8879   0.8884   0.8109\n",
      "hepatitis       Ripper               0.8026   0.7925   0.8026   0.8040   0.9026\n",
      "hepatitis       C4.5                 0.7523   0.7527   0.7523   0.7584   0.8387\n",
      "hepatitis       CostSensitive C4.5   0.7535   0.7532   0.7535   0.7642   0.8388\n",
      "ljubljana       Ripper               0.7177   0.6650   0.7177   0.7031   0.9298\n",
      "ljubljana       C4.5                 0.6154   0.6175   0.6154   0.6242   0.7110\n",
      "ljubljana       CostSensitive C4.5   0.6095   0.6118   0.6095   0.6213   0.7047\n",
      "cargood         Ripper               0.9574   0.9584   0.9574   0.9607   0.9754\n",
      "cargood         C4.5                 0.9904   0.9903   0.9904   0.9908   0.9957\n",
      "cargood         CostSensitive C4.5   0.9905   0.9903   0.9905   0.9907   0.9965\n",
      "chess           Ripper               0.9838   0.9845   0.9838   0.9860   0.9878\n",
      "chess           C4.5                 0.9970   0.9969   0.9970   0.9970   0.9989\n",
      "chess           CostSensitive C4.5   0.9961   0.9961   0.9961   0.9962   0.9988\n",
      "zoo3            Ripper               0.9128   0.9111   0.9128   0.9117   0.9540\n",
      "zoo3            C4.5                 0.9383   0.9346   0.9383   0.9347   0.9663\n",
      "zoo3            CostSensitive C4.5   0.9602   0.9494   0.9602   0.9413   0.9874\n",
      "flare           Ripper               0.9505   0.9395   0.9505   0.9334   0.9869\n",
      "flare           C4.5                 0.9493   0.9412   0.9493   0.9360   0.9836\n",
      "flare           CostSensitive C4.5   0.8989   0.9162   0.8989   0.9380   0.9224\n",
      "yeast3          Ripper               0.9378   0.9360   0.9378   0.9361   0.9717\n",
      "yeast3          C4.5                 0.9286   0.9287   0.9286   0.9293   0.9593\n",
      "yeast3          CostSensitive C4.5   0.9275   0.9271   0.9275   0.9274   0.9599\n",
      "abalone19       Ripper               0.9851   0.9796   0.9851   0.9742   0.9980\n",
      "abalone19       C4.5                 0.9737   0.9747   0.9737   0.9757   0.9855\n",
      "abalone19       CostSensitive C4.5   0.9703   0.9732   0.9703   0.9764   0.9816\n",
      "segment0        Ripper               0.9882   0.9883   0.9882   0.9886   0.9908\n",
      "segment0        C4.5                 0.9928   0.9928   0.9928   0.9930   0.9943\n",
      "segment0        CostSensitive C4.5   0.9927   0.9927   0.9927   0.9928   0.9950\n",
      "pageblocks      Ripper               0.8398   0.8134   0.8398   0.8374   0.9705\n",
      "pageblocks      C4.5                 0.8389   0.8381   0.8389   0.8383   0.9008\n",
      "pageblocks      CostSensitive C4.5   0.8303   0.8328   0.8303   0.8366   0.8807\n"
     ]
    }
   ],
   "source": [
    "# Storage for results\n",
    "results_data = []\n",
    "\n",
    "print(f\"{'Dataset':<15} {'Algorithm':<20} {'Acc':<8} {'F1':<8} {'Recall':<8} {'Prec':<8} {'Spec':<8}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    X, y = load_dataset(dataset_name, DATASETS_PATH)\n",
    "    \n",
    "    if X is None:\n",
    "        continue\n",
    "\n",
    "    for model_name, model_inst in models.items():\n",
    "        \n",
    "        # Metrics storage for averaging across 5 runs * 5 folds = 25 scores\n",
    "        run_metrics = {'acc': [], 'f1': [], 'rec': [], 'prec': [], 'spec': []}\n",
    "\n",
    "        # 5 Runs\n",
    "        for run_idx in range(5):\n",
    "            # Use different random state for each run to vary the folds\n",
    "            kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42 + run_idx)\n",
    "            \n",
    "            for train_idx, test_idx in kf.split(X, y):\n",
    "                X_train, X_test = X[train_idx], X[test_idx]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "                # Clone/Reset model\n",
    "                if model_name == \"Ripper\":\n",
    "                    clf = lw.RIPPER() # Wittgenstein models need fresh init\n",
    "                else:\n",
    "                    # Sklearn models can be cloned or re-instantiated\n",
    "                    params = model_inst.get_params()\n",
    "                    clf = DecisionTreeClassifier(**params)\n",
    "\n",
    "                try:\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    y_pred = clf.predict(X_test)\n",
    "\n",
    "                    # Calculate Metrics\n",
    "                    # Note: 'weighted' average handles class imbalance/multiclass gracefully\n",
    "                    run_metrics['acc'].append(accuracy_score(y_test, y_pred))\n",
    "                    run_metrics['f1'].append(f1_score(y_test, y_pred, average='weighted', zero_division=0))\n",
    "                    run_metrics['rec'].append(recall_score(y_test, y_pred, average='weighted', zero_division=0))\n",
    "                    run_metrics['prec'].append(precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
    "                    run_metrics['spec'].append(calculate_specificity(y_test, y_pred))\n",
    "                \n",
    "                except Exception as e:\n",
    "                    # Fallback for failures (common with Ripper on some data types)\n",
    "                    pass\n",
    "\n",
    "        # Aggregate Results\n",
    "        res = {\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Algorithm\": model_name,\n",
    "            \"Accuracy\": np.mean(run_metrics['acc']),\n",
    "            \"F1-Score\": np.mean(run_metrics['f1']),\n",
    "            \"Recall\": np.mean(run_metrics['rec']),\n",
    "            \"Precision\": np.mean(run_metrics['prec']),\n",
    "            \"Specificity\": np.mean(run_metrics['spec'])\n",
    "        }\n",
    "        results_data.append(res)\n",
    "        \n",
    "        print(f\"{res['Dataset']:<15} {res['Algorithm']:<20} \"\n",
    "              f\"{res['Accuracy']:.4f}   {res['F1-Score']:.4f}   \"\n",
    "              f\"{res['Recall']:.4f}   {res['Precision']:.4f}   {res['Specificity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172e62c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
