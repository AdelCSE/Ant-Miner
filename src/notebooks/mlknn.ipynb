{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0c3ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    hamming_loss as hl,)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    label_ranking_loss,\n",
    "    coverage_error,\n",
    "    average_precision_score,)\n",
    "\n",
    "import multilabel_knn as mlk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d6df055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/adel/Documents/Code/Ant-Miner/datasets/multi_label/cleaned/emotions.csv')\n",
    "labels = [col for col in data.columns if 'label' in col]\n",
    "X = data.drop(columns=labels)\n",
    "y = data[labels]\n",
    "y = y.values.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe45a505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multilabel_knn.multilabel_knn.multilabel_kNN at 0x7edb9db26990>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Initialize the MLkNN classifier\n",
    "model = mlk.multilabel_kNN(k=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f601f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, likelihood = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41c1a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy \n",
    "def accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    accs = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        accs.append(accuracy_score(y_true[:, i], y_pred[:, i]))\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "485b64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dense = y_pred.toarray().astype(int)\n",
    "\n",
    "y_proba_dense = likelihood.toarray().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71ea4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.8727 - Subset Accuracy: 22.4719 - F1 Score (Micro): 66.4858 - F1 Score (Macro): 64.0434 - Hamming Loss: 0.2313 - Ranking Loss: 0.2606 - Coverage Error: 3.4101 - Average Precision: 42.0457\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(y_test, y_pred_dense)\n",
    "sub_acc = accuracy_score(y_test, y_pred_dense)\n",
    "f1_micro = f1_score(y_test, y_pred_dense, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred_dense, average='macro')\n",
    "hm = hl(y_test, y_pred_dense)\n",
    "rl = label_ranking_loss(y_test, y_proba_dense)\n",
    "ce = coverage_error(y_test, y_proba_dense)\n",
    "ap = average_precision_score(y_test, y_proba_dense, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {acc*100:.4f} - Subset Accuracy: {sub_acc*100:.4f} - F1 Score (Micro): {f1_micro*100:.4f} - F1 Score (Macro): {f1_macro*100:.4f} - Hamming Loss: {hm:.4f} - Ranking Loss: {rl:.4f} - Coverage Error: {ce:.4f} - Average Precision: {ap*100:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1c558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
